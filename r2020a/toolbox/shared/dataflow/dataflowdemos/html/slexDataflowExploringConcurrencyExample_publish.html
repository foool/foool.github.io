
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Exploring Different Forms of Concurrency with Dataflow</title><meta name="generator" content="MATLAB 9.2"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-05-01"><meta name="DC.source" content="slexDataflowExploringConcurrencyExample_publish.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Exploring Different Forms of Concurrency with Dataflow</h1><!--introduction--><p>This example uses dataflow, a data-driven domain in Simulink, to run a communication system simulation multithreaded. In this example we show how Simulink can use inherent parallelism and pipeline parallelism to partition the model into multiple threads. This system shows the improvement in bit error rate (BER) performance when using log-likelihood ratio (LLR) instead of hard decision demodulation in a convolutionally coded communication link.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">About Dataflow</a></li><li><a href="#2">Introduction</a></li><li><a href="#3">Different Forms of Parallelism</a></li><li><a href="#4">Single-Threaded Simulation</a></li><li><a href="#5">Inherent Parallelism in the Model</a></li><li><a href="#6">Increasing Concurrency by Removing Data Dependency</a></li><li><a href="#7">Multithreaded Simulation</a></li><li><a href="#8">Thread Allocation Results</a></li><li><a href="#9">Summary</a></li></ul></div><h2 id="1">About Dataflow</h2><p>With dataflow, blocks inside domain execute based on arrival of data as opposed to Simulink's sample time, and models are automatically partitioned into concurrent threads that accelerate simulation and increase data throughput. For an introduction to dataflow see the <a href="matlab:web(fullfile(matlabroot,'toolbox','shared','dataflow','dataflowdemos','html','slexDataflowIntroductionExample_publish.html'))">Introduction to Dataflow for Multithreading in Simulink</a> example. To take advantage of dataflow domain, hence multithreaded simulation, your model or section of your model must only have discrete-time blocks. Using Dataflow Subsystem we can create dataflow regions in a model. The Dataflow Subsystem delineates the region of the model where dataflow semantics, as opposed to Simulink's sample time is used to sort and execute blocks. Moreover, you cannot have blocks that access time, require a Simulink solver, or do not support code generation. In Simulink, you create a dataflow domain using the Dataflow Subsystem block. Inputs to Dataflow Subsystem block are not associated with a sample time. Signals outputed from the Dataflow Subsystem are associated with the same sample time as the input signal prior to entering the Dataflow Subsystem. All the blocks inside Dataflow Subsystem block form a dataflow region in the model.</p><h2 id="2">Introduction</h2><p>This example shows a communication system in dataflow that compares BER performance when using LLR instead of hard decision demodulation in the decoder. This example has one transmitter, an AWGN Channel and three receivers. The three receivers use different decoding techniques to compare the BER of each approach. Bit error rate computation is shown inside DisplayErrors Subsystem for comparing the performance of the three receivers.</p><img vspace="5" hspace="5" src="slexDataflowExploringConcurrencyExample_publish_01.png" alt=""> <h2 id="3">Different Forms of Parallelism</h2><p>A Simulink model could have inherent parallelism and pipeline parallelism. Inherent parallelism is when different blocks of a model can run in parallel without any dependencies. Pipeline parallelism is when different blocks operate in a chain where data goes from one block to next in the chain. To create pipeline parallelism pipeline delays need to be introduced between blocks in this chain that breaks data dependency and enables the blocks to run in parallel. For example, in this communication system the 3 Viterbi Decoders can run independently. This is inherent parallelism present in the model. Within one receiver the Demodulator, Viterbi Decoder and Error Rate Calculator are in a chain and would need pipeline delays between them to break data dependency and enable pipeline parallelism.</p><h2 id="4">Single-Threaded Simulation</h2><p>In this section we simulate a model of the communication system that does not use dataflow. This simulation executes the blocks in the model using only a single thread. Execution time is measured using the output of the sim command and include only run-time of the model and does not include time for model update or terminate. We will use this time later to compare against the run-time of multithreaded model to measure actual speedup.</p><pre class="codeoutput">Simulation execution time for single-threaded model = 9.33s
</pre><h2 id="5">Inherent Parallelism in the Model</h2><p>There is lots of inherent parallelism in this model since the three receivers can run independently. However, the receivers are data dependent on one transmitter. This causes a bottleneck since the transmitter needs to complete its processing before any receivers start processing. Without introducing pipeline delays only the inherent parallelism present in the model can be utilized to run the dataflow region multithreaded. You can analyze parallelism in the model by using the Dataflow Multithreading Analysis app. You can open this app by double-clicking on the Dataflow Multithreading Analysis App block in the model. In the app you can see that three threads are used by dataflow region taking advantage of the inherent parallelism in the model. In the thread timing diagram, we can see that all the encoder blocks run before any blocks in receiver run. In this app you can view speedup analysis information for different delays by choosing the menu option "Analysis-&gt;Performance Tradeoff-&gt;Speedup &amp; Threads vs. Delays". The app shows for 0 pipeline delays the estimated speedup that can be obtained is only about 2.0x. Actual speedup computed by measuring the execution time taken by the model using multiple threads and dividing it with the execution time taken by a model using a single thread is shown below. This number which shows the speedup obtained without any pipeline parallelism is shown below. We will add pipeline delays and create pipeline parallelism in the next section.</p><pre class="codeoutput">Simulation execution time for multithreaded model using only inherent parallelism = 3.86s
Actual speedup with dataflow using only inherent parallelism with 0 pipeline delays: 2.4x
</pre><img vspace="5" hspace="5" src="slexDataflowExploringConcurrencyExample_publish_02.png" alt=""> <h2 id="6">Increasing Concurrency by Removing Data Dependency</h2><p>By allowing pipelining of the data dependent blocks we can increase concurrency in this model. Simulink can increase parallelism in the model by introducing pipeline delays between the blocks in the dataflow domain and therefore breaking the dependency between the blocks. Dataflow Multithreading Analysis app shows that using 5 pipeline delays can enable the blocks in the model to run using 6 threads gaining a speedup of about 4.4x. We set this value in the Dataflow configuration block. Once you add pipeline delays by increasing the latency, data dependency between the blocks is removed and Simulink can run more blocks in parallel using multiple threads. The thread timing diagram below shows usage of 6 threads with the number of pipeline delays set to 5. We can see in this diagram both encoder and some receiver blocks are running in parallel. This would not be possible without pipelining the dataflow region.</p><img vspace="5" hspace="5" src="slexDataflowExploringConcurrencyExample_publish_03.png" alt=""> <h2 id="7">Multithreaded Simulation</h2><p>By creating a dataflow region in the model and adding pipeline delays to break data dependencies it enabled Simulink to automatically partition the model into concurrent execution threads. When simulating this model it uses multiple threads and dataflow region can run at an estimated speedup of 4.4 times faster than the single-threaded version. When we run this model, the blocks in the dataflow region will run in 6 different threads in parallel. We can measure the amount of speedup obtained in the dataflow model by dividing the execution time taken by the model using multiple threads with the execution time taken by a model using a single thread. The speedup number is computed and shown below. This number could be different from the estimated speedup shown in the Dataflow Multithreading Analysis app. This difference could arise from thread overhead and cache performance when running the model in multithreaded mode. The estimated speedup considers only blocks inside dataflow domain, while the actual time measurement includes all the blocks in the model, including the source and the display blocks.</p><pre class="codeoutput">Simulation execution time for multithreaded model using pipeline parallelism and inherent parallelism = 2.83s
Actual speedup with dataflow using both pipeline parallelism and inherent parallelism: 3.3x
</pre><h2 id="8">Thread Allocation Results</h2><p>The partitioning of the dataflow region into threads can be seen by turning thread highlighting "on" using the menu option "Display-&gt;Highlight Dataflow Threads". For this model, 6 different threads used by the dataflow region are shown using 6 different colors. For example, all the 3 Viterbi Decoder blocks run in different threads. The Thread Legend window can be used to selectively highlight only some threads for inspecting the model.</p><p><img vspace="5" hspace="5" src="slexDataflowExploringConcurrencyExampleHighlightThreadsPix.png" alt=""> </p><img vspace="5" hspace="5" src="slexDataflowExploringConcurrencyExample_publish_04.png" alt=""> <h2 id="9">Summary</h2><p>This example shows how Simulink can take a communication system simulation model using dataflow and automatically partition it into concurrent execution threads and run the model using multiple threads. This example shows an estimated speedup of 4.4 times over single-threaded simulation using 6 threads. Dataflow Multithreading Analysis app shows how different blocks are scheduled to run in parallel and how introducing pipeline delays between blocks breaks data dependency between blocks and increases concurrency. Note that depending on the desktop computer system and the processor you are using, the numbers and visualization showed could be different when you run the same model in your computer. These numbers and analysis were published on a Windows desktop computer with Intel&reg; Xeon&reg; CPU E5-1650 v3 @ 3.4 GHz 6 Cores 12 Threads processor.</p><p class="footer">Copyright 2016-2017 The MathWorks, Inc.<br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Exploring Different Forms of Concurrency with Dataflow
% This example uses dataflow, a data-driven domain in Simulink, to
% run a communication system simulation multithreaded. In this example we
% show how Simulink can use inherent parallelism and pipeline parallelism
% to partition the model into multiple threads. This system shows the
% improvement in bit error rate (BER) performance when using log-likelihood
% ratio (LLR) instead of hard decision demodulation in a convolutionally
% coded communication link.

%% About Dataflow
% With dataflow, blocks inside domain execute based on arrival of data as
% opposed to Simulink's sample time, and models are automatically
% partitioned into concurrent threads that accelerate simulation and
% increase data throughput. For an introduction to dataflow see the
% <matlab:web(fullfile(matlabroot,'toolbox','shared','dataflow','dataflowdemos','html','slexDataflowIntroductionExample_publish.html'))
% Introduction to Dataflow for Multithreading in Simulink> example. To take
% advantage of dataflow domain, hence multithreaded simulation, your model
% or section of your model must only have discrete-time blocks. Using
% Dataflow Subsystem we can create dataflow regions in a model. The
% Dataflow Subsystem delineates the region of the model where dataflow
% semantics, as opposed to Simulink's sample time is used to sort and
% execute blocks. Moreover, you cannot have blocks that access time,
% require a Simulink solver, or do not support code generation. In
% Simulink, you create a dataflow domain using the Dataflow Subsystem
% block. Inputs to Dataflow Subsystem block are not associated with a
% sample time. Signals outputed from the Dataflow Subsystem are associated
% with the same sample time as the input signal prior to entering the
% Dataflow Subsystem. All the blocks inside Dataflow Subsystem block form a
% dataflow region in the model.

% Copyright 2016-2017 The MathWorks, Inc.

%% Introduction
% This example shows a communication system in dataflow that compares BER
% performance when using LLR instead of hard decision demodulation in the
% decoder. This example has one transmitter, an AWGN Channel and three
% receivers. The three receivers use different decoding techniques to
% compare the BER of each approach. Bit error rate computation is shown
% inside DisplayErrors Subsystem for comparing the performance of the three
% receivers.
model_name = 'slexDataflowExploringConcurrencyExample';
open_system(model_name);
open_system([model_name '/Subsystem']); % Open Dataflow Subsystem

%% Different Forms of Parallelism
% A Simulink model could have inherent parallelism and pipeline
% parallelism. Inherent parallelism is when different blocks of a model can
% run in parallel without any dependencies. Pipeline parallelism is when
% different blocks operate in a chain where data goes from one block to
% next in the chain. To create pipeline parallelism pipeline delays need to
% be introduced between blocks in this chain that breaks data dependency
% and enables the blocks to run in parallel. For example, in this
% communication system the 3 Viterbi Decoders can run independently. This
% is inherent parallelism present in the model. Within one receiver the
% Demodulator, Viterbi Decoder and Error Rate Calculator are in a chain and
% would need pipeline delays between them to break data dependency and
% enable pipeline parallelism.

%% Single-Threaded Simulation
% In this section we simulate a model of the communication system that does
% not use dataflow. This simulation executes the blocks in the model using
% only a single thread. Execution time is measured using the output of the
% sim command and include only run-time of the model and does not include
% time for model update or terminate. We will use this time later to
% compare against the run-time of multithreaded model to measure actual
% speedup.
singleThreadedModel = 'slexDataflowSingleThreadedExample';
open_system(singleThreadedModel);
singleThreadedExecTime = simulateExample(singleThreadedModel,'StopTime','1000');
fprintf('Simulation execution time for single-threaded model = %.2fs/n', singleThreadedExecTime);
close_system(singleThreadedModel, 0);

%% Inherent Parallelism in the Model
% There is lots of inherent parallelism in this model since the three
% receivers can run independently. However, the receivers are data
% dependent on one transmitter. This causes a bottleneck since the
% transmitter needs to complete its processing before any receivers start
% processing. Without introducing pipeline delays only the inherent
% parallelism present in the model can be utilized to run the dataflow
% region multithreaded. You can analyze parallelism in the model by using
% the Dataflow Multithreading Analysis app. You can open this app by
% double-clicking on the Dataflow Multithreading Analysis App block in the
% model. In the app you can see that three threads are used by dataflow
% region taking advantage of the inherent parallelism in the model. In
% the thread timing diagram, we can see that all the encoder blocks run
% before any blocks in receiver run. In this app you can view speedup
% analysis information for different delays by choosing the menu option
% "Analysis->Performance Tradeoff->Speedup & Threads vs. Delays". The app
% shows for 0 pipeline delays the estimated speedup that can be obtained is
% only about 2.0x. Actual speedup computed by measuring the execution time
% taken by the model using multiple threads and dividing it with the
% execution time taken by a model using a single thread is shown below.
% This number which shows the speedup obtained without any pipeline
% parallelism is shown below. We will add pipeline delays and create
% pipeline parallelism in the next section.
set_param([model_name '/Subsystem/Dataflow Configuration'], 'Latency', '0');
set_param(model_name, 'SimulationCommand', 'Update');
close all;
multithreadedExecTime = simulateExample(model_name,'StopTime','1000');
dataflow.internal.visuals.openBlockVisual(model_name,struct(...
    'AnalysisType',1,'ScreenScaling',[60 400 750 650],'BackGround','white'));
fprintf('Simulation execution time for multithreaded model using only inherent parallelism = %.2fs/n', ...
         multithreadedExecTime);
fprintf('Actual speedup with dataflow using only inherent parallelism with 0 pipeline delays: %.1fx/n', singleThreadedExecTime/multithreadedExecTime);

%% Increasing Concurrency by Removing Data Dependency
% By allowing pipelining of the data dependent blocks we can increase
% concurrency in this model. Simulink can increase parallelism in the model
% by introducing pipeline delays between the blocks in the dataflow domain
% and therefore breaking the dependency between the blocks. Dataflow
% Multithreading Analysis app shows that using 5 pipeline delays can enable
% the blocks in the model to run using 6 threads gaining a speedup of about
% 4.4x. We set this value in the Dataflow configuration block. Once you add pipeline delays by increasing the
% latency, data dependency between the blocks is removed and Simulink can
% run more blocks in parallel using multiple threads. The thread timing
% diagram below shows usage of 6 threads with the number of pipeline delays
% set to 5. We can see in this diagram both encoder and some receiver
% blocks are running in parallel. This would not be possible without
% pipelining the dataflow region.
close all;
set_param([model_name '/Subsystem/Dataflow Configuration'], 'Latency', '5');
set_param(model_name, 'SimulationCommand', 'Update');
dataflow.internal.visuals.openBlockVisual(model_name,struct(...
    'AnalysisType',3,'ScreenScaling',[60 400 750 500],'BackGround','white'));

%% Multithreaded Simulation
% By creating a dataflow region in the model and adding pipeline delays to
% break data dependencies it enabled Simulink to automatically partition
% the model into concurrent execution threads. When simulating this model
% it uses multiple threads and dataflow region can run at an estimated
% speedup of 4.4 times faster than the single-threaded version. When we run
% this model, the blocks in the dataflow region will run in 6 different
% threads in parallel. We can measure the amount of speedup obtained in the
% dataflow model by dividing the execution time taken by the model using
% multiple threads with the execution time taken by a model using a single
% thread. The speedup number is computed and shown below. This number could
% be different from the estimated speedup shown in the Dataflow
% Multithreading Analysis app. This difference could arise from thread
% overhead and cache performance when running the model in multithreaded
% mode. The estimated speedup considers only blocks inside dataflow domain,
% while the actual time measurement includes all the blocks in the model,
% including the source and the display blocks.
multithreadedExecTime = simulateExample(model_name,'StopTime','1000');
fprintf(['Simulation execution time for multithreaded model using pipeline' ...
         ' parallelism and inherent parallelism = %.2fs/n'], multithreadedExecTime);
fprintf(['Actual speedup with dataflow using both pipeline parallelism and' ...
         ' inherent parallelism: %.1fx/n'], singleThreadedExecTime/multithreadedExecTime);

%% Thread Allocation Results
% The partitioning of the dataflow region into threads can be seen by
% turning thread highlighting "on" using the menu option
% "Display->Highlight Dataflow Threads". For this model, 6 different
% threads used by the dataflow region are shown using 6 different colors.
% For example, all the 3 Viterbi Decoder blocks run in different threads.
% The Thread Legend window can be used to selectively highlight only some
% threads for inspecting the model.
%
% <<slexDataflowExploringConcurrencyExampleHighlightThreadsPix.png>>
%
set_param(model_name, 'HighlightDataflowThreads', 'on');
set_param(model_name, 'SimulationCommand', 'Update');
print('-dpng',['-s' model_name '/Subsystem'], [model_name 'HighlightThreadsPix.png']);

%% Summary
% This example shows how Simulink can take a communication system
% simulation model using dataflow and automatically partition it into
% concurrent execution threads and run the model using multiple threads.
% This example shows an estimated speedup of 4.4 times over single-threaded
% simulation using 6 threads. Dataflow Multithreading Analysis app shows
% how different blocks are scheduled to run in parallel and how introducing
% pipeline delays between blocks breaks data dependency between blocks and
% increases concurrency. Note that depending on the desktop computer system
% and the processor you are using, the numbers and visualization showed
% could be different when you run the same model in your computer. These
% numbers and analysis were published on a Windows desktop computer with
% Intel(R) Xeon(R) CPU E5-1650 v3 @ 3.4 GHz 6 Cores 12 Threads processor.

close_system(model_name, 0);
close all;


##### SOURCE END #####
--></body></html>